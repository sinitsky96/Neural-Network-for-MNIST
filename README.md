# Neural-Network-for-MNIST
In this project I've implemented a two-layered NN without using any functions from the Pytorch  library except for the use of data loading and tensor manipulation. 
The PDF with my name on it contains two parts :
1) Mathematical development of the derivative of the loss function with regards to the SoftMax activation function.
2) A summary of the Architecture I've developed a two part practical section, one part with the purpose to achieve good generalization and another one for the purpose of inspecting the outcome of overfitting your model and its applications on you train/test loss and accuracy.
These practical parts are located in their own folders with the script for training the model and evaluating it.
furthermore I've included a .pkl file with the weights after running the models for ease of use. 
